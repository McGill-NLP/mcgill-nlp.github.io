---
title: 'You could have said that instead: Improving Chatbots with Natural Language
  Feedback'
venue: Findings
openAccessPdf:
  url: https://www.aclweb.org/anthology/2020.findings-emnlp.221.pdf
  status: HYBRID
  license: CCBY
  disclaimer: 'Notice: This abstract is extracted from the open access paper or abstract
    available at https://arxiv.org/abs/2010.07261, which is subject to the license
    by the author or copyright owner provided with this content. Please go to the
    source to verify the license and copyright information for your use.'
names: Makesh Narsimhan Sreedhar, Kun Ni, Siva Reddy
tags:
- Findings
link: https://arxiv.org/abs/2010.07261
author: Siva Reddy
categories: Publications
layout: paper

---

*{{ page.names }}*

**{{ page.venue }}**

{% include display-publication-links.html pub=page %}

## Abstract

The ubiquitous nature of dialogue systems and their interaction with users generate an enormous amount of data. Can we improve chatbots using this data? A self-feeding chatbot improves itself by asking natural language feedback when a user is dissatisfied with its response and uses this feedback as an additional training sample. However, user feedback in most cases contains extraneous sequences hindering their usefulness as a training sample. In this work, we propose a generative adversarial model that converts noisy feedback into a plausible natural response in a conversation. The generator’s goal is to convert the feedback into a response that answers the user’s previous utterance and to fool the discriminator which distinguishes feedback from natural responses. We show that augmenting original training data with these modified feedback responses improves the original chatbot performance from 69.94%to 75.96% in ranking correct responses on the PERSONACHATdataset, a large improvement given that the original model is already trained on 131k samples.